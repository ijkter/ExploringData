# Machine Learning

## 特征工程

### 特征归一化（Feature Normalization）

#### 为什么要对数值类型的特征归一化？

为了消除特征之间的量纲影响，通过对特征进行归一化处理，可以将所有的特征都统一到一个大致相同的数值区间内，使得不同指标之间具有可比性。

#### 特征归一化的方法

- 线性函数归一化（Min-Max Scaling）
  
  对原始数据进行线性变化，使其结果映射到[0, 1]的范围，实现对原数据的等比缩放。假设最大值为 $X_{max}$，最小值为 $X_{min}$，那么归一化公式为：

  $$ X_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}}$$

- 零均值归一化（Z-Score Normalization）
  
  将原始数据映射到均值为 0，标准差为 1 的分布上。假设均值为 $\mu$，标准差为 $\sigma$，那么归一化公式为：

  $$ z = \frac{x - \mu}{\sigma}$$

#### 为什么通过梯度下降法求解的模型通常需要归一化？

在学习速览相同的情况下，通过将量纲差距较大的特征归一化，可以使特征的更细速度变得更为一致，容易更快地通过梯度下降找到最优解。

### 类别性特征

#### 数据处理时如何处理类别型特征

- 序号编码（Ordinal Encoding）
  
  序号编码常用于处理类别间**具有大小关系**的特征，按照大小关系对类别型特征赋予一个数值 ID，使数据转换后依然保留大小关系。

- 独热编码（One-Hot Encoding）

  独热编码通常用于处理类别间**不具有大小关系**的特征，将特征转变为一个稀疏向量，只有某一维取值为 1，其他位置取值为 0。对于类别取值较多的情况要注意以下问题：
  - 使用稀疏向量来节省空间
  - 配合特征选择降低维度

- 二进制编码（Binary Encoding）

  首先用序号编码给每个类别赋予一个类别 ID，然后用类别 ID 对应的二进制编码作为结果。利用二进制对 ID 进行映哈希映射，最终得到的 0/1 特征向量，相较独热码节省了存储空间。

### 高维特征

#### 高维特征可能出现的问题

- 在 K 近邻算法中，高维空间下两点之间的距离很难得到有效衡量
- 在逻辑回归模型中，参数的数量会随着维度的增高而增加，容易引起过拟合
- 通常只有部分维度是对分类、预测有帮助

#### 组合特征

为提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。

#### 如何有效地找到组合特征

- 基于决策树的特征组合寻找方法
  
  采用梯度提升决策树的方法，每次都在之前构建的决策树的残差上构建下一棵决策树。根据构造出来的决策树，每一条从根节点到叶节点的路径都可以看成一种特征组合。

### 文本表示模型

#### 词袋模型（Bag of Words）

- 核心思想

  将每篇文章看成一袋子词，并忽略每个词出现的顺序。

- 过程
  
  将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量，向量中的每一维代表一个单词，而该维对应的权重（常由 TF-IDF 计算而得）则反映了这个词在原文章的重要程度。

- 缺点
  
  将文章进行单次级别划分，每个单词所表达的含义与其组合含义可能相去甚远。

#### TF-IDF（Term Frequency-Inverse Document Frequency）

- 核心思想
  
  如果一个单词在非常多的文章里面都出现，那么它可能是一个比较通用的词汇，对于区分某篇文章特殊语义的贡献较小，因此对其权重做一定惩罚。

- 公式：
  $$ TF - IDF(t,d)=TF(t,d) \times IDF(t) $$
  其中，TF(t,d) 为单词 t 在文档 d 中出现的频率，IDF(t) 是逆文档频率，用来衡量单词 t 对表达语义所起的重要性，表示为：
  $$ IDF(t)=\log \frac{文章总数}{包含单词 t 的文章总数 + 1}$$


#### N-gram 模型

- 核心思想

  在词袋模型的基础上，将连续出现的 n 个词（n ≤ N）组成的词组（N-gram）也作为一个单独的特征放到向量表示中。

- 词干抽取（Word Stemming）
  
  将不同词性的单词统一成为同一词干的形式。

#### 主题模型（Topic Model）

用于从文本库中发现有代表性的主题（得到每个主题上面词的分布特性），并且能够计算出每篇文章的主题分布。

#### 词嵌入模型（Word Embedding）

- 核心思想
  
  将每个词都映射成低维空间（通常 K=50~300 维）上的一个稠密向量（Dense Vector）。K 维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那么直观。

### Word2Vec

常用词嵌入模型之一，是一种浅层的神经网络模型，有两种网络结构：
- CBOW（Continues Bag of Words）：根据上下文出现的词语来预测当前词的生成概率
- Skip-gram：根据当前词来预测上下文中各词的生成概率

### 训练数据不足的问题

#### 处理方法

根据模型信息的来源：
1. 训练数据中蕴含的信息
2. 模型的形成过程中（包括构造、学习、推理等）提供的先验信息

故在训练数据不足时，模型需要更多的先验信息：
- 先验信息作用在模型上，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件
- 先验信息直接施加在数据集上，即根据特定的先验假设去调整、变换或拓展训练数据，让其展现出更多的、更有的信息，以利于后续模型的训练和学习

#### 图像训练数据不足时的处理方法

- 基于模型的方法
  
  简化模型（将非线性模型简化为线性模型）、添加约束项以缩小假设空间（如 L1/L2 正则项）、集成学习、Dropout 超参数等

- 基于数据的方法
  
  - 一定程度的随机旋转、平移、缩放、裁剪、填充、左右翻转等
  - 对图像中的像素添加噪声扰动，比如：椒盐噪声、高斯白噪声等
  - 改变图像的颜色、亮度、清晰度、对比度、锐度等

## 模型评估

### 评估指标

#### 准确率（Accuracy）

- 定义
  
  分类正确的样本占总样本个数的比例，即

  $$ Accuracy = \frac{n_{correct}}{n_{}} $$

  其中 $n_{correct}$ 为被正确分类的样本个数，$n_{total}$ 为总样本的个数。

- 局限性
  
  当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的主要因素。如：负样本占整体样本的 99%，将全体样本都预测为负样本都可以获得 99% 的准确率。

#### 精确率（Precision）和召回率（Recall）

- 精确率

  分类正确的正样本个数占**分类器判定为正样本**的样本个数的比例。

- 召回率
  
  分类正确的正样本个数占**真正的正样本**个数的比例。

- 关联
  
  为提高精确率，分类器尽量在“更有把握”时将样本判定为正样本，这可能会因过于保守而漏掉“没有把握”的正样本，导致召回率降低。故在模型评估时，应同时关注精确率和召回率。

#### 综合反应模型性能

- P-R（Precision Recall）曲线

  横轴是召回率，纵轴是精确率。对于一个排序模型来说，其 P-R 曲线上的一个点代表着，在某一阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时反回结果对应的召回率和精确率。

- F1 score

- 精确率和召回率的调和平均值，定义为：F1 = $\frac{2 \times precision \times recall}{precision + recall}$
- 综合地反映一个排序模型的性能

#### 均方根误差（Root Mean Square Error，RMSE）

- 定义
  
  常用于衡量回归模型的好坏。一般情况下，RMSE 能够很好地反映回归模型预测值与真实值的偏离程度。

- 计算公式

  $$ RMSE = \sqrt{\frac{\sum_{i=1}^n(y_i-\hat{y_i})^2}{n}} $$
  
  其中，$y_i$ 是第 i 个样本点的真实值，$\hat{y_i}$ 是第 i 个样本点的预测值，n 是样本点的个数。

- 局限性
  
  若存在个别偏离程度非常大的利离群点时，即使离群点数量非常少，也会让 RMSE 指标变得很差。应对方法：
  
  - 在数据预处理阶段过滤掉被判定为离群点的噪声数据
  - 若不认为离群点为噪声，则需要进一步提高模型能力，将离群点产生的机制建模进去
  - 寻找更合适的指标评估当前模型。如：MAPE。

#### 平均绝对百分比误差（Mean Absolute Percent Error，MAPE）

- 定义
  
  $$ MAPE = \sum_{i=1}^{n}|\frac{y_i - \hat{y_i}}{y_i}|\times\frac{100}{n} $$

- 与 RMSE 对比
  
  鲁棒性更强，与 RMSE 对比相当把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响。

### ROC

#### 定义

ROC（Receiver Operating Characteristic Curve） 曲线即“受试者特征工程曲线”。曲线横轴为假阳性率（False Positive Rate，FPR），纵轴为真阳性率（True Positive Rate， TPR）。其计算方法分别为：$FPR = \frac{FP}{N}$ 和 $TPR = \frac{TP}{P}$，其中，P 是真实的正样本数量，N 是真实的负样本数量，TP 是 P 个正样本中被分类器预测为正样本的个数，FP 是 N 个负样本中被分类器预测为正样本的个数。

假设有 10 位患者，3 位患病，7 位无病。经医院诊断出 3 位患病，其中 2 位为真患病，1 位误诊，则 P = 3， TP = 2， N = 7， FP = 1，故 FPR = 1/7, TPR = 2/3，对于“医院”这个分类器，这组分类器结果对于 ROC 上（1/7，2/3）这一点。

#### AUC

- 定义

  AUC（Area Under Curve） 是 ROC 曲线下的面积大小（沿 ROC 横轴做积分），该值能够量化地反映给予 ROC 曲线衡量的模型性能。

- 含义
  
  因为 ROC 曲线一般处于 y=x 下方，所以AUC 取值一般在 0.5 ～ 1 之间。AUC值越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。

#### 与 P-R 曲线对比

当正负样本的分布发生变化时，ROC 曲线的形状能够基本保持不变，而 P-R 曲线形状一般会发生比较剧烈的变化。

- 在正负样本不均衡的情况下，ROC 曲线能更加稳定地反应模型本身的好坏，故适用场景更多
- 观察模型在特定数据集上的表现，P-R 曲线能够更直观地反应其性能

### 余弦距离

#### 定义

机器学习中常将特征表示为向量的形式，所以在分析两个**特征向量之间的相似性**时常用余弦相似度来表示。对于向量 A 和 B，其余弦相似度为：$cos(A, B) = \frac{A \dot B}{||A||_2||B||_2}$，取值范围为 [-1, 1]，相同向量之间的相似度为 1。若要以类似距离的方式表示：**余弦距离 = 1 - 余弦相似度**，则余弦距离取值范围为 [0, 1]，相同向量的余弦距离为 0。

#### 使用余弦距离而不使用欧氏距离的场景

- 一对长度差距大、但内容相近的文本，使用词频或词向量作为特征时
  - 在特征空间中的欧式距离通常很大
  - 其夹角可能很小，因而余弦相似度高

- 总体差别
  - 欧氏距离：数值上的绝对差异
  - 余弦距离：方向上的相对差异

#### 余弦距离是否是一个严格定义的距离

- 距离的定义
  
  在一个集合中，若每一对元素均可唯一确定一个实数，使得三条距离公理（正定性，对称性，三角不等式）成立，则该实数可称为这对元素之间的距离。

  - 正定性：dist(A, B) >= 0
  - 对称性：dist(A, B) = dist(B, A)
  - 三角不等式：dist(A, B)

- 余弦距离满足正定性、对称性，而不满足三角不等式，故不是严格定义的距离

### A/B 测试

#### 定义

验证模型最终效果，相比旧算法、旧模型，新算法、新模型的效果是否有提升。

#### 为什么需要在线 A/B 测试

1. 离线评估无法完全消除模型过拟合的影响，因此离线评估结果无法完全替代线上评估结果
2. 离线评估无法完全还原线上工程环境（延迟、数据丢失、标签数据缺失）
3. 线上系统某些商业指标在离线评估中无法计算。离线评估一般针对模型本身进行评估，模型相关的其他指标如商业指标，往往无法直接获得。如：上新推荐模型，离线评估往往关注 ROC 曲线、P-R 曲线的改进；而新模型带来的用户点击率、留存时长、PV 访问量的变化，需要由线上 A/B 测试来评估

#### 线上 A/B 测试的方法

对用户进行分桶，对实验组施以新模型，对照组施以旧模型。分桶要点：样本独立性（同一个用户每次只能分到一个桶中）和采样方式的无偏性（分桶选取用户 ID 随机）。 

### 模型评估方法

#### Holdout 检验

- 将原始样本集合随机划分成训练集和验证集，训练集用于模型训练，验证集用于模型验证，包括绘制 ROC 曲线、计算精确度和召回率等指标来评估模型性能。

- 局限性

  在验证集上计算出来的评估指标与原始分组有很大关系。

#### 交叉检验

- k-fold 交叉检验

  1. 将全部样本划分成 k （通常为 10）个大小相等的样本子集
  2. 依次遍历 k 个子集，每次都将当前子集作为验证集，其余所有子集当训练集，进行模型的训练和评估
  3. 最后将 k 次评估指标的平均值作为最终的评估指标

- 留一验证
  
  每次留下 1 个样本作为验证集，其余所有样本作为训练集。样本总数为 n，遍历 n 个样本进行 n 次验证，再将评估指标取均值得最终评估指标。当 n 很大时，时间开销会很大。

#### 自助法

- 定义

  对于总数为 n 的样本合集，进行 n 次有放回的随机抽样，得到大小为 n 的训练集。n 次采样过程中，有的样本会被重复采样，完全没被抽出过的样本作为验证集，进行模型验证。
  
  当样本规模比较小时，对样本集进行划分会让训练集进一步减小而影响训练模型效果，使用自助法能够维持训练集的样本规模。

- 当 n 趋于无穷大时，最终有多少数据从未被选择？

  一个样本在一次抽取中未被抽中的概率为 $(1-\frac{1}{n})$，n 次抽样未被抽中的概率为 $(1-\frac{1}{n})^n$。当 n 趋于无穷大，有
  
  $$ lim_{n\infty}(1-\frac{1}{n})^n = \frac{1}{e} ≈ 0.368 $$

  故当样本量很大时，大约有 36.8 的样本从未被选择过。

### 过拟合与欠拟合

#### 过拟合

- 定义

  模型对于训练数据拟合过度，表现为训练集合上表现很好，而测试集和新数据上表现上较差。

- 降低方法

  1. 从数据角度，应获取更多训练数据。更多的样本能够让模型学习到更多有效的特征减小噪声影响。在实验数据有限、无法直接增加的情况下，可以：
     - 通过一定规则扩充训练数据
     - 使用生产式对抗网络合成大量新数据
  2. 从模型角度，降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，应适当降低模型复杂度。如：
     - 神经网络中减少网络层数、神经元个数
     - 决策树中降低的深度、剪枝
  3. 正则化方法。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以 L2 正则化为例：
     $$C = C_0 + \frac{\lambda}{2n}·\sum_i\omega_i^2$$
     在优化原来的目标函数 $C_0$ 的同时，也能避免权值过大带来的过拟合风险。
  4. 集成学习方法。将多个模型集成在一起，以降低单一模型的过拟合风险。

#### 欠拟合

- 定义

  模型在训练和与测试表现都不好。

- 降低方法

  1. 添加新特征。当特征不足或现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘“上下文特征”“ID 类特征”“组合特征”等的新特征，往往能够取得更好的效果。深度学习中可以丰富特征的模型有：
     - 因子分解机
     - 梯度提升决策树
     - Deep-crossing
  2. 增加模型复杂度。过于简单的模型学习能力较差，增加模型复杂度可以提高拟合能力。如：
     - 在线性模型中添加高次项
     - 在神经网络模型中增加网络层数、神经元个数
  3. 减小正则化系数。正则化是用于解决过拟合的，但当模型欠拟合时，应当有针对性地减小正则化系数。
